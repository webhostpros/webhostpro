#!/usr/bin/env python3
import os, re, glob, time
from pathlib import Path

BACKUP_NAME = "index.webalizer.bak.html"

def is_webalizer_index(html: str) -> bool:
    return ("Generated by The Webalizer" in html) or ("Webalizer Version" in html)

def is_whp_index(html: str) -> bool:
    if not html:
        return False
    h = html.lower()
    return ("traffic insights" in h) and ("top pages" in h or "monthly reports" in h)

def process_dir(d: Path):
    index_path = d / "index.html"
    if not index_path.exists():
        return False

    st = d.stat()
    uid, gid = st.st_uid, st.st_gid

    current_html = index_path.read_text(errors="ignore")
    backup_path = d / BACKUP_NAME

    # Always find latest usage first. If there is no usage file, nothing to build.
    latest = find_latest_usage_html(d)
    if not latest or not latest.exists():
        return False

    # If we still have a real Webalizer index at any point, capture it once.
    if is_webalizer_index(current_html) and not backup_path.exists():
        write_file_atomic(backup_path, current_html, uid, gid, 0o644)

    # Domain and summary source preference:
    # 1) Saved Webalizer backup (best)
    # 2) Current Webalizer index (if still present)
    # 3) Folder name fallback plus month from latest usage (works for WHP-only folders)
    if backup_path.exists():
        source_html = backup_path.read_text(errors="ignore")
        domain = extract_domain_from_webalizer_source(source_html, fallback=d.name)
        summary = parse_current_row_from_index(source_html) or {}
    elif is_webalizer_index(current_html):
        domain = extract_domain_from_webalizer_source(current_html, fallback=d.name)
        summary = parse_current_row_from_index(current_html) or {}
    else:
        domain = d.name
        summary = {}

    # Ensure timeframe is always set from latest usage file name
    m = re.search(r"usage_(\d{6})\.html", latest.name)
    if m:
        summary["yyyymm"] = m.group(1)

    month_links = build_month_links_from_files(d)
    generated = time.strftime("%Y-%m-%d %H:%M:%S %Z")

    usage_html = latest.read_text(errors="ignore")
    top_referrers, top_pages = extract_top_referrers_and_pages(usage_html, limit=25)

    modern = build_modern_index(
        domain=domain,
        generated=generated,
        summary=summary,
        month_links_html=month_links,
        top_referrers=top_referrers,
        top_pages=top_pages
    )

    write_file_atomic(index_path, modern, uid, gid, 0o644)
    return True

def strip_tags(s: str) -> str:
    s = re.sub(r"<.*?>", "", s, flags=re.DOTALL)
    s = s.replace("&nbsp;", " ").replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
    return " ".join(s.split()).strip()

def yyyymm_to_label(yyyymm: str) -> str:
    if not yyyymm or len(yyyymm) != 6 or not yyyymm.isdigit():
        return "—"
    y = int(yyyymm[:4])
    m = int(yyyymm[4:6])
    months = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]
    if 1 <= m <= 12:
        return f"{months[m-1]} {y}"
    return yyyymm

def write_file_atomic(path: Path, content: str, uid: int, gid: int, mode: int = 0o644):
    tmp = path.with_suffix(path.suffix + f".tmp.{os.getpid()}")
    tmp.write_text(content, encoding="utf-8")
    os.chown(tmp, uid, gid)
    os.chmod(tmp, mode)
    os.replace(tmp, path)

def find_latest_usage_html(d: Path):
    files = sorted(d.glob("usage_[0-9][0-9][0-9][0-9][0-9][0-9].html"))
    return files[-1] if files else None

def build_month_links_from_files(d: Path) -> str:
    files = sorted(d.glob("usage_[0-9][0-9][0-9][0-9][0-9][0-9].html"), reverse=True)
    if not files:
        return "<p>No monthly reports found.</p>"
    items = []
    for f in files:
        yyyymm = f.name.replace("usage_", "").replace(".html", "")
        items.append(f'<li><a href="{f.name}">{yyyymm_to_label(yyyymm)}</a></li>')
    return "<ul>" + "\n".join(items) + "</ul>"

def parse_current_row_from_index(index_html: str):
    m = re.search(r'<A HREF="usage_(\d{6})\.html".*?</A></TD>(.*?)</TR>', index_html, re.IGNORECASE | re.DOTALL)
    if not m:
        return {}
    yyyymm = m.group(1)
    row = m.group(2)
    nums = re.findall(r'ALIGN=right><FONT SIZE="-1">([^<]+)</FONT>', row, re.IGNORECASE)
    if len(nums) < 10:
        return {}

    def to_int(s):
        s = s.strip().replace(",", "")
        return int(s) if s.isdigit() else None

    return {
        "yyyymm": yyyymm,
        "monthly_sites": to_int(nums[4]),
        "monthly_visits": to_int(nums[6]),
        "monthly_hits": to_int(nums[9]),
    }

def extract_domain_from_webalizer_source(html: str, fallback: str) -> str:
    m = re.search(r"<TITLE>\s*Usage Statistics for\s+(.+?)\s*-", html, re.IGNORECASE)
    if m:
        return strip_tags(m.group(1)).strip()
    return fallback

def looks_like_referrer(s: str) -> bool:
    s = (s or "").strip()
    if not s:
        return False

    sl = s.lower()
    bad_prefix = ("total ", "code ", "hits per", "files per", "pages per", "sites per", "visits per", "kbytes per")
    if sl.startswith(bad_prefix):
        return False

    # Reject percentage-only / numeric labels like "0.92%"
    if "%" in s:
        return False

    # Must contain at least one letter to be a real domain/referrer name
    if not re.search(r"[a-zA-Z]", s):
        # Allow explicit URLs even if weird, but they will contain letters anyway
        return False

    # URLs or domain-like strings
    if sl.startswith(("http://", "https://")):
        return True

    # domain-like: contains a dot, no spaces
    if "." in s and " " not in s:
        return True

    return False

def looks_like_page(s: str) -> bool:
    s = (s or "").strip().lower()
    if not s:
        return False

    # Reject totals / system rows
    bad_prefix = (
        "total ", "code ", "hits per", "files per",
        "pages per", "sites per", "visits per", "kbytes per"
    )
    if s.startswith(bad_prefix):
        return False

    # Must be a path
    if not s.startswith("/"):
        return False

    # Strip querystring
    s = s.split("?", 1)[0]

    # Allowed “page” extensions
    allowed_ext = (
        ".php",
        ".html",
        ".htm",
        ".asp",
        ".aspx",
        ".jsp",
        ".cfm",
        ".cgi",
        ".pl"
    )

    # If path ends with allowed extension → page
    if s.endswith(allowed_ext):
        return True

    # Allow directory index pages like "/about/" or "/services"
    # but reject file assets
    if "." not in s.split("/")[-1]:
        return True

    return False

def extract_top_referrers_and_pages(usage_html: str, limit: int = 25):
    tables = re.findall(r"<TABLE\b.*?</TABLE>", usage_html, re.IGNORECASE | re.DOTALL)

    def parse_table_auto(table_html: str, kind: str):
        rows = re.findall(r"<TR\b.*?>.*?</TR>", table_html, re.IGNORECASE | re.DOTALL)
        parsed = []
        for r in rows:
            if re.search(r"<TH\b", r, re.IGNORECASE):
                continue
            cols = re.findall(r"<TD\b.*?>\s*(.*?)\s*</TD>", r, re.IGNORECASE | re.DOTALL)
            cols = [strip_tags(c) for c in cols]
            cols = [c for c in cols if c]
            if len(cols) < 2:
                continue
            parsed.append(cols)

        if not parsed:
            return []

        max_cols = max(len(r) for r in parsed)

        # Pick label column
        best_label_idx = None
        best_score = 0
        for idx in range(min(max_cols, 8)):
            score = 0
            for r in parsed[:120]:
                if idx >= len(r):
                    continue
                s = r[idx]
                if kind == "ref" and looks_like_referrer(s):
                    score += 1
                if kind == "page" and looks_like_page(s):
                    score += 1
            if score > best_score:
                best_score = score
                best_label_idx = idx

        if best_label_idx is None or best_score < 3:
            return []

        # Score numeric columns so we can choose "Hits" and optionally "Visits"
        col_stats = []
        for idx in range(min(max_cols, 10)):
            if idx == best_label_idx:
                continue
            ints = []
            for r in parsed[:200]:
                if idx >= len(r):
                    continue
                t = r[idx].replace(",", "").strip()
                if t.isdigit():
                    ints.append(int(t))
            if len(ints) < 5:
                continue
            avg = sum(ints) / max(1, len(ints))
            col_stats.append((idx, avg, len(ints)))

        if not col_stats:
            return []

        # Hits column: usually the largest average
        col_stats.sort(key=lambda x: x[1], reverse=True)
        hits_idx = col_stats[0][0]
        hits_avg = col_stats[0][1]

        # Visits column: next best numeric column that is smaller than hits (if present)
        visits_idx = None
        if kind == "page":
            for idx, avg, _cnt in col_stats[1:]:
                if 0 < avg <= hits_avg:
                    visits_idx = idx
                    break

        items = []
        for r in parsed:
            if best_label_idx >= len(r):
                continue
            label = r[best_label_idx]

            if kind == "ref" and not looks_like_referrer(label):
                continue
            if kind == "page" and not looks_like_page(label):
                continue

            def get_int(i):
                if i is None or i >= len(r):
                    return None
                t = r[i].replace(",", "").strip()
                return int(t) if t.isdigit() else None

            hits = get_int(hits_idx)
            if kind == "ref":
                items.append({"label": label, "value": hits})
            else:
                visits = get_int(visits_idx) if visits_idx is not None else None
                items.append({"label": label, "hits": hits, "visits": visits})

        if kind == "ref":
            items.sort(key=lambda x: (x["value"] is None, -(x["value"] or 0)))
        else:
            items.sort(key=lambda x: (x["hits"] is None, -(x["hits"] or 0)))

        return items[:limit]

    best_ref = []
    best_page = []

    for t in tables:
        ref_items = parse_table_auto(t, "ref")
        if len(ref_items) > len(best_ref):
            best_ref = ref_items

        page_items = parse_table_auto(t, "page")
        if len(page_items) > len(best_page):
            best_page = page_items

    return best_ref[:limit], best_page[:limit]

def render_top_list(title: str, items, value_label: str):
    if not items:
        return f"""
        <div class="section">
          <h2>{title}</h2>
          <div class="empty">No data found in the latest monthly report.</div>
        </div>
        """

def render_top_pages(title: str, items):
    if not items:
        return f"""
        <div class="section">
          <h2>{title}</h2>
          <div class="empty">No data found in the latest monthly report.</div>
        </div>
        """

    rows = []
    for i in items:
        hits = f"{i['hits']:,}" if isinstance(i.get("hits"), int) else "—"
        visits = f"{i['visits']:,}" if isinstance(i.get("visits"), int) else "—"
        rows.append(f"<tr><td>{i['label']}</td><td class='num'>{hits}</td><td class='num'>{visits}</td></tr>")

    return f"""
    <div class="section">
      <h2>{title}</h2>
      <div class="tablewrap">
        <table class="t">
          <thead>
            <tr>
              <th>Name</th>
              <th class="num">Hits</th>
              <th class="num">Visits</th>
            </tr>
          </thead>
          <tbody>
            {''.join(rows)}
          </tbody>
        </table>
      </div>
    </div>
    """

    rows = []
    for i in items:
        if isinstance(i.get("value"), int):
            val = f"{i['value']:,}"
        else:
            val = "—"
        rows.append(f"<tr><td>{i['label']}</td><td class='num'>{val}</td></tr>")

    return f"""
    <div class="section">
      <h2>{title}</h2>
      <div class="tablewrap">
        <table class="t">
          <thead><tr><th>Name</th><th class="num">{value_label}</th></tr></thead>
          <tbody>
            {''.join(rows)}
          </tbody>
        </table>
      </div>
    </div>
    """

def build_modern_index(domain: str, generated: str, summary: dict, month_links_html: str, top_referrers, top_pages):
    yyyymm = summary.get("yyyymm", "")
    month_label = yyyymm_to_label(yyyymm)

    def fmt(n):
        return f"{n:,}" if isinstance(n, int) else "—"

    ref_block = render_top_list("Top Referrers (Top 25)", top_referrers, "Hits")
    pages_block = render_top_pages("Top Pages (Top 25)", top_pages)

    return f"""<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Traffic Insights for {domain}</title>

<style>
  :root {{
    color-scheme: dark;
    --bg:#0b1220;
    --panel:#121a2b;
    --muted:#8ea0c2;
    --text:#e9f0ff;
    --teal:#006c6e;
  }}

  body {{
    margin:0;
    background:var(--bg);
    font:14px/1.5 system-ui,-apple-system,Segoe UI,Roboto,Arial;
    color:var(--text);
  }}

  .wrap {{
    max-width:1100px;
    margin:0 auto;
    padding:22px 18px 36px;
  }}

  h1 {{
    margin:0 0 6px;
    font-size:20px;
    font-weight:700;
  }}

  .sub {{
    color:var(--muted);
    margin:0 0 18px;
  }}

  .grid {{
    display:grid;
    grid-template-columns:repeat(3,minmax(0,1fr));
    gap:12px;
    margin:16px 0 18px;
  }}

  .card {{
    background:var(--panel);
    border-radius:16px;
    padding:14px;
  }}

  .k {{
    color:var(--muted);
    font-size:12px;
    margin:0 0 6px;
  }}

  .v {{
    font-size:22px;
    font-weight:750;
    margin:0;
  }}

  .pill {{
    display:inline-block;
    background:rgba(0,108,110,.22);
    color:#b9ffff;
    padding:4px 10px;
    border-radius:999px;
    font-size:12px;
  }}

  .section {{
    background:var(--panel);
    border-radius:18px;
    padding:14px;
    margin-top:12px;
  }}

  .section h2 {{
    margin:0 0 10px;
    font-size:14px;
    color:#dfe8ff;
  }}

  .empty {{
    color:var(--muted);
    font-size:12px;
    padding:6px 0 2px;
  }}

  .months ul {{
    margin:0;
    padding-left:18px;
    columns:3;
    gap:24px;
  }}

  .months a {{
    color:#cfe3ff;
    text-decoration:none;
  }}

  .months a:hover {{
    text-decoration:underline;
  }}

  .t {{
    width:100%;
    border-collapse:collapse;
  }}

  .t th,.t td {{
    padding:10px 8px;
    border-bottom:1px solid rgba(255,255,255,.06);
    vertical-align:top;
  }}

  .t th {{
    text-align:left;
    font-size:12px;
    color:#dfe8ff;
  }}

  .num {{
    text-align:right;
    white-space:nowrap;
  }}

 .t th.num { text-align:right; }

  .tablewrap {{
    overflow:auto;
  }}

  @media (max-width:860px) {{
    .grid {{ grid-template-columns:1fr; }}
    .months ul {{ columns:1; }}
  }}
</style>
</head>

<body>
  <div class="wrap">
    <h1>Traffic Insights <span class="pill">{domain}</span></h1>
    <p class="sub">Timeframe: <strong>{month_label}</strong> (monthly totals). Generated {generated}.</p>

    <div class="grid">
<div class="card"><p class="k">Visitors (Sites)</p><p class="v">{fmt(summary.get("monthly_sites"))}</p></div>
<div class="card"><p class="k">Hits</p><p class="v">{fmt(summary.get("monthly_hits"))}</p></div>
<div class="card"><p class="k">Visits</p><p class="v">{fmt(summary.get("monthly_visits"))}</p></div>    </div>

    {ref_block}
    {pages_block}

    <div class="section months">
      <h2>Monthly Reports</h2>
      {month_links_html}
    </div>
  </div>
</body>
</html>
"""

def process_dir(d: Path):
    index_path = d / "index.html"
    if not index_path.exists():
        return False

    st = d.stat()
    uid, gid = st.st_uid, st.st_gid

    current_html = index_path.read_text(errors="ignore")
    backup_path = d / BACKUP_NAME

    # If Webalizer index appears, capture it once
    if is_webalizer_index(current_html) and not backup_path.exists():
        write_file_atomic(backup_path, current_html, uid, gid, 0o644)

    # Decide what to use as the source for domain + summary
    if backup_path.exists():
        source_html = backup_path.read_text(errors="ignore")
    elif is_webalizer_index(current_html):
        source_html = current_html
    elif is_whp_index(current_html):
        # No backup exists, but we can still re-render using current UI as source
        source_html = current_html
    else:
        return False

    # Domain + summary
    domain = extract_domain_from_webalizer_source(source_html, fallback=d.name)
    summary = parse_current_row_from_index(source_html) or {}

    # If summary missing (because source is WHP UI), fall back to latest usage month label
    latest = find_latest_usage_html(d)
    if (not summary.get("yyyymm")) and latest and latest.exists():
        m = re.search(r"usage_(\d{6})\.html", latest.name)
        if m:
            summary["yyyymm"] = m.group(1)

    month_links = build_month_links_from_files(d)
    generated = time.strftime("%Y-%m-%d %H:%M:%S %Z")

    top_referrers, top_pages = ([], [])
    if latest and latest.exists():
        usage_html = latest.read_text(errors="ignore")
        top_referrers, top_pages = extract_top_referrers_and_pages(usage_html, limit=25)

    modern = build_modern_index(
        domain=domain,
        generated=generated,
        summary=summary,
        month_links_html=month_links,
        top_referrers=top_referrers,
        top_pages=top_pages
    )

    write_file_atomic(index_path, modern, uid, gid, 0o644)
    return True
def main():
    changed = 0
    seen = set()

    # Find every Webalizer index.html under /home/*/tmp/webalizer (including ssl/*)
    for idx in glob.glob("/home/*/tmp/webalizer/**/index.html", recursive=True):
        if "/home/virtfs/" in idx:
            continue
        d = str(Path(idx).parent)
        if d in seen:
            continue
        seen.add(d)

        try:
            if process_dir(Path(d)):
                changed += 1
        except Exception:
            continue

    print(f"whp-webalizer-ui-render: updated {changed} webalizer index pages")
if __name__ == "__main__":
    main()